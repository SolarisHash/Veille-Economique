#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Module d'analyse th√©matique des donn√©es de veille √©conomique
"""

import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import json
import yaml
from collections import defaultdict, Counter

class AnalyseurThematiques:
    """Analyseur th√©matique pour classifier les informations trouv√©es"""
    
    def __init__(self, thematiques_config: List[str]):
        """Initialisation de l'analyseur avec TOUS les mots-cl√©s"""
        self.thematiques = thematiques_config
        self.config = self._charger_config_mots_cles()
        self.seuil_pertinence = 0.1  # ‚úÖ SEUIL ABAISS√â
        self.periode_recente = timedelta(days=30)
        
        # ‚úÖ AJOUT CRITIQUE : D√©finition des mots-cl√©s th√©matiques
        self.thematiques_mots_cles = {
            'evenements': [
                'porte ouverte', 'portes ouvertes', 'conf√©rence', 'salon', 'forum',
                'rencontre', '√©v√©nement', 'manifestation', 'colloque', 's√©minaire',
                'd√©couvrir', 'venez d√©couvrir'
            ],
            'recrutements': [
                'recrutement', 'nous recrutons', 'embauche', 'recrute', 'offre emploi',
                'offres emploi', 'CDI', 'CDD', 'stage', 'alternance', 'apprentissage',
                'carri√®re', 'poste', 'cherchons', 'rejoindre notre √©quipe'
            ],
            'vie_entreprise': [
                'ouverture', 'fermeture', 'd√©m√©nagement', 'implantation', 'd√©veloppement',
                'expansion', 'partenariat', 'collaboration', 'fusion', 'acquisition',
                'restructuration', 'rachat'
            ],
            'innovations': [
                'am√©lioration', 'modernisation', 'innovation', 'd√©veloppe', 'nouveau',
                'nouveau produit', 'nouveau service', 'lancement', 'brevets', 'R&D',
                'recherche d√©veloppement', 'technologie', 'prototype'
            ],
            'exportations': [
                'export', 'exportation', 'international', '√©tranger', 'march√© international',
                'contrat export', 'd√©veloppement international', 'commerce ext√©rieur'
            ],
            'aides_subventions': [
                'subvention', 'aide', 'financement', 'soutien', 'cr√©dit',
                'subventionn√©', 'aid√©', 'pr√™t', 'investissement public', 'dispositif d\'aide'
            ],
            'fondation_sponsor': [
                'fondation', 'sponsor', 'sponsoring', 'm√©c√©nat', 'partenaire',
                'soutien', 'dons', 'charitable', 'solidarit√©', 'engagement social'
            ]
        }
            
    def _charger_config_mots_cles(self) -> Dict:
        """Chargement de la configuration des mots-cl√©s"""
        try:
            with open('config/parametres.yaml', 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                return config.get('mots_cles', {})
        except FileNotFoundError:
            return self._config_mots_cles_defaut()
            
    def _config_mots_cles_defaut(self) -> Dict:
        """Configuration par d√©faut des mots-cl√©s"""
        return {
            'evenements': ['porte ouverte', 'conf√©rence', 'salon', '√©v√©nement'],
            'recrutements': ['recrutement', 'embauche', 'offre emploi', 'CDI'],
            'vie_entreprise': ['ouverture', 'd√©veloppement', 'partenariat'],
            'innovations': ['innovation', 'nouveau produit', 'R&D'],
            'exportations': ['export', 'international', '√©tranger'],
            'aides_subventions': ['subvention', 'aide', 'financement'],
            'fondation_sponsor': ['fondation', 'sponsor', 'm√©c√©nat']
        }
         
    def _analyser_entreprise(self, resultat: Dict) -> Dict:
        """‚úÖ CORRIG√â : Analyse d'entreprise adapt√©e au format exact de vos donn√©es"""
        entreprise = resultat['entreprise'].copy()
        
        # Initialisation des r√©sultats th√©matiques
        resultats_thematiques = {
            thematique: {
                'trouve': False,
                'score_pertinence': 0.0,
                'sources': [],
                'details': [],
                'derniere_mention': None
            }
            for thematique in self.thematiques
        }
        
        # Analyse des donn√©es par th√©matique
        donnees_thematiques = resultat.get('donnees_thematiques', {})
        
        print(f"    üìã Donn√©es re√ßues pour {entreprise.get('nom', 'N/A')}: {list(donnees_thematiques.keys())}")
        
        for thematique, donnees in donnees_thematiques.items():
            if thematique in self.thematiques:
                print(f"    üéØ Analyse th√©matique directe: {thematique}")
                
                if isinstance(donnees, dict):
                    try:
                        # Calcul du score
                        score = self._calculer_score_avec_vos_donnees(donnees, thematique)
                        print(f"         üíØ Score calcul√©: {score:.3f} (seuil: {self.seuil_pertinence})")
                        
                        if score > self.seuil_pertinence:
                            print(f"         ‚úÖ Th√©matique {thematique} VALID√âE !")
                            
                            resultats_thematiques[thematique]['trouve'] = True
                            resultats_thematiques[thematique]['score_pertinence'] = score
                            if 'web_general' not in resultats_thematiques[thematique]['sources']:
                                resultats_thematiques[thematique]['sources'].append('web_general')
                            
                            # Extraction des informations
                            informations_extraites = self._extraire_infos_format_reel(donnees)
                            
                            detail = {
                                'source': 'web_general',
                                'score': score,
                                'informations': informations_extraites,
                                'timestamp': datetime.now().isoformat(),
                                'raw_data': donnees
                            }
                            resultats_thematiques[thematique]['details'].append(detail)
                        else:
                            print(f"         ‚ùå Score trop faible: {score:.3f} <= {self.seuil_pertinence}")
                            
                    except Exception as e:
                        print(f"         ‚ùå Erreur calcul score {thematique}: {e}")
                        continue
                else:
                    print(f"         ‚ö†Ô∏è Format donn√©es inattendu: {type(donnees)}")
        
        # Calcul des scores finaux
        for thematique in resultats_thematiques:
            self._calculer_score_final(resultats_thematiques[thematique])
        
        # Ajout des r√©sultats √† l'entreprise
        entreprise['analyse_thematique'] = resultats_thematiques
        entreprise['score_global'] = self._calculer_score_global(resultats_thematiques)
        entreprise['thematiques_principales'] = self._identifier_thematiques_principales(resultats_thematiques)
        entreprise['date_analyse'] = datetime.now().isoformat()
        
        print(f"    üèÜ Score global final: {entreprise['score_global']:.3f}")
        print(f"    üéØ Th√©matiques principales: {entreprise['thematiques_principales']}")
        
        return entreprise

    def _calculer_score_avec_vos_donnees(self, donnees: Dict, thematique: str) -> float:
        """‚úÖ CORRIG√â : Calcul de score adapt√© au format exact de vos donn√©es"""
        score_total = 0.0
        
        print(f"           üìä Analyse des donn√©es: {list(donnees.keys())}")
        
        # 1. Score bas√© sur la pertinence calcul√©e par votre syst√®me
        if 'pertinence' in donnees:
            pertinence_brute = donnees['pertinence']
            # Normalisation : vos scores peuvent √™tre > 1.0
            score_pertinence = min(pertinence_brute, 1.0)
            score_total += score_pertinence
            print(f"           üéØ Pertinence: {pertinence_brute} ‚Üí {score_pertinence}")
        
        # 2. Score bas√© sur les mots-cl√©s trouv√©s
        if 'mots_cles_trouves' in donnees:
            mots_cles = donnees['mots_cles_trouves']
            if isinstance(mots_cles, list) and len(mots_cles) > 0:
                score_mots_cles = min(len(mots_cles) * 0.15, 0.4)
                score_total += score_mots_cles
                print(f"           üîë Mots-cl√©s ({len(mots_cles)}): +{score_mots_cles}")
        
        # 3. Score bas√© sur les extraits textuels
        if 'extraits_textuels' in donnees:
            extraits = donnees['extraits_textuels']
            if isinstance(extraits, list) and len(extraits) > 0:
                score_extraits = self._analyser_extraits_vos_donnees(extraits, thematique)
                score_total += score_extraits
                print(f"           üìÑ Extraits ({len(extraits)}): +{score_extraits}")
        
        # 4. Bonus pour URLs multiples
        if 'urls' in donnees:
            urls = donnees['urls']
            if isinstance(urls, list) and len(urls) > 1:
                bonus_urls = min(len(urls) * 0.05, 0.2)
                score_total += bonus_urls
                print(f"           üîó URLs ({len(urls)}): +{bonus_urls}")
        
        # Score final avec limite r√©aliste
        score_final = min(score_total, 0.9)
        print(f"           üèÜ Score final: {score_final}")
        
        return score_final

    def _analyser_extraits_vos_donnees(self, extraits: List[Dict], thematique: str) -> float:
        """‚úÖ CORRIG√â : Analyse des extraits dans votre format exact"""
        if not extraits:
            return 0.0
        
        score_extraits = 0.0
        mots_cles_thematique = self.thematiques_mots_cles.get(thematique, [])
        
        print(f"             üìã Analyse de {len(extraits)} extraits pour {thematique}")
        
        for i, extrait in enumerate(extraits[:3]):  # Top 3 extraits
            if not isinstance(extrait, dict):
                continue
            
            # Construction du texte √† analyser
            texte_parts = []
            for champ in ['titre', 'description', 'extrait_complet']:
                if champ in extrait and isinstance(extrait[champ], str):
                    texte_parts.append(extrait[champ])
            
            texte_complet = ' '.join(texte_parts).lower()
            
            if len(texte_complet) > 10:  # Texte significatif
                # Comptage des mots-cl√©s th√©matiques
                mots_trouves = [mot for mot in mots_cles_thematique if mot.lower() in texte_complet]
                
                if mots_trouves:
                    score_extrait = min(len(mots_trouves) * 0.1, 0.3)
                    score_extraits += score_extrait
                    print(f"               {i+1}. {len(mots_trouves)} mots-cl√©s ‚Üí +{score_extrait}")
                else:
                    # Bonus minimal pour contenu pertinent
                    if any(terme in texte_complet for terme in ['entreprise', 'soci√©t√©', 'activit√©', 'service']):
                        score_extraits += 0.05
                        print(f"               {i+1}. Contenu g√©n√©ral ‚Üí +0.05")
        
        return min(score_extraits, 0.5)

    def _extraire_infos_format_reel(self, donnees: Dict) -> Dict:
        """‚úÖ CORRIG√â : Extraction d'informations selon votre format de donn√©es"""
        informations = {
            'timestamp': datetime.now().isoformat()
        }
        
        # Extraction directe des champs
        champs_directs = ['mots_cles_trouves', 'urls', 'pertinence', 'type']
        
        for champ in champs_directs:
            if champ in donnees:
                informations[champ] = donnees[champ]
        
        # Traitement des extraits textuels
        if 'extraits_textuels' in donnees:
            extraits = donnees['extraits_textuels']
            if isinstance(extraits, list) and len(extraits) > 0:
                informations['extraits_textuels'] = extraits[:3]  # Top 3
                
                # R√©sum√©s
                titres = []
                descriptions = []
                urls_extraits = []
                
                for extrait in extraits[:3]:
                    if isinstance(extrait, dict):
                        if 'titre' in extrait and extrait['titre']:
                            titres.append(extrait['titre'])
                        if 'description' in extrait and extrait['description']:
                            descriptions.append(extrait['description'])
                        if 'url' in extrait and extrait['url']:
                            urls_extraits.append(extrait['url'])
                
                if titres:
                    informations['resume_titres'] = ' | '.join(titres)
                if descriptions:
                    informations['resume_descriptions'] = ' | '.join(descriptions[:2])
                if urls_extraits:
                    informations['urls_sources'] = urls_extraits
        
        # M√©tadonn√©es
        informations['nb_champs_remplis'] = len([v for v in informations.values() if v])
        informations['source_data_format'] = 'format_reel_detecte'
        
        return informations
        
    def _analyser_source(self, donnees: Dict, source: str, resultats_thematiques: Dict):
        """Analyse d'une source de donn√©es avec capture compl√®te des informations"""
        print(f"    üîç Analyse source: {source}")
        
        for thematique, info in donnees.items():
            if thematique in resultats_thematiques:
                print(f"      üéØ Analyse th√©matique: {thematique}")
                
                # Calcul du score de pertinence
                score = self._calculer_score_pertinence(info, source)
                print(f"         üíØ Score calcul√©: {score:.2f}")
                
                if score > self.seuil_pertinence:
                    print(f"         ‚úÖ Score > seuil ({self.seuil_pertinence})")
                    
                    resultats_thematiques[thematique]['trouve'] = True
                    resultats_thematiques[thematique]['score_pertinence'] = max(
                        resultats_thematiques[thematique]['score_pertinence'], score
                    )
                    
                    # Ajout de la source
                    if source not in resultats_thematiques[thematique]['sources']:
                        resultats_thematiques[thematique]['sources'].append(source)
                        
                    # ‚úÖ EXTRACTION COMPL√àTE DES INFORMATIONS
                    informations_extraites = self._extraire_informations_completes(info, source)
                    
                    # Ajout des d√©tails avec TOUTES les informations
                    detail = {
                        'source': source,
                        'score': score,
                        'informations': informations_extraites,  # ‚Üê INFORMATIONS COMPL√àTES
                        'timestamp': datetime.now().isoformat(),
                        'raw_data': info  # ‚Üê DONN√âES BRUTES pour debug
                    }
                    resultats_thematiques[thematique]['details'].append(detail)
                    
                    print(f"         üìä Informations extraites: {len(informations_extraites)} cl√©s")
                    print(f"         üìã D√©tails ajout√©s: {list(informations_extraites.keys())}")
                else:
                    print(f"         ‚ö™ Score trop faible ({score:.2f} <= {self.seuil_pertinence})")
    
    def _extraire_informations_completes(self, info: Dict, source: str) -> Dict:
        """Extraction COMPL√àTE des informations avec tous les d√©tails textuels"""
        informations = {
            'source': source,
            'timestamp': datetime.now().isoformat()
        }
        
        # 1. Mots-cl√©s trouv√©s
        if 'mots_cles_trouves' in info:
            informations['mots_cles'] = info['mots_cles_trouves']
            print(f"           üîë Mots-cl√©s: {info['mots_cles_trouves']}")
        
        # 2. URL source
        if 'url' in info:
            informations['url'] = info['url']
            print(f"           üîó URL: {info['url']}")
        
        # 3. Type d'information
        if 'type' in info:
            informations['type'] = info['type']
        
        # 4. ‚úÖ EXTRAITS TEXTUELS (le plus important!)
        if 'extraits_textuels' in info:
            informations['extraits_textuels'] = info['extraits_textuels']
            print(f"           üìÑ Extraits textuels: {len(info['extraits_textuels'])}")
            
            # Debug des extraits
            for i, extrait in enumerate(info['extraits_textuels'][:2]):
                titre = extrait.get('titre', 'Sans titre')
                description = extrait.get('description', 'Sans description')
                print(f"              {i+1}. {titre[:40]} - {description[:60]}...")
        
        # 5. ‚úÖ EXTRAITS CONTEXTUELS (site officiel)
        if 'extraits_contextuels' in info:
            informations['extraits_contextuels'] = info['extraits_contextuels']
            print(f"           üéØ Extraits contextuels: {len(info['extraits_contextuels'])}")
            
            for i, extrait in enumerate(info['extraits_contextuels'][:2]):
                mot_cle = extrait.get('mot_cle', 'N/A')
                contexte = extrait.get('contexte', 'N/A')
                print(f"              {i+1}. [{mot_cle}] {contexte[:50]}...")
        
        # 6. ‚úÖ R√âSUM√â DE CONTENU
        if 'resume_contenu' in info:
            informations['resume_contenu'] = info['resume_contenu']
            print(f"           üìù R√©sum√©: {info['resume_contenu'][:60]}...")
        
        # 7. ‚úÖ URLS COLLECT√âES
        urls_collectees = []
        if 'urls' in info:
            urls_collectees.extend(info['urls'])
        if 'url' in info:
            urls_collectees.append(info['url'])
        
        if urls_collectees:
            informations['urls_sources'] = list(set(urls_collectees))  # D√©dupliqu√©
            print(f"           üåê URLs: {len(urls_collectees)} collect√©es")
        
        # 8. ‚úÖ PERTINENCE ET M√âTADONN√âES
        if 'pertinence' in info:
            informations['score_pertinence'] = info['pertinence']
        
        # 9. ‚úÖ TOUS LES AUTRES CHAMPS DISPONIBLES
        for cle, valeur in info.items():
            if cle not in informations and cle not in ['raw_data']:
                informations[cle] = valeur
        
        print(f"           ‚úÖ Total informations extraites: {len(informations)} champs")
        return informations
                    
    def _calculer_score_pertinence(self, info: Dict, source: str) -> float:
        """Calcul du score de pertinence avec validation stricte"""
        score_base = 0.0
        
        # Score bas√© sur le nombre de mots-cl√©s trouv√©s
        if 'mots_cles_trouves' in info:
            nb_mots_cles = len(info['mots_cles_trouves'])
            # Score plus conservateur
            score_base = min(nb_mots_cles * 0.15, 0.6)  # Maximum 0.6 au lieu de 1.0
            
        # Score bas√© sur la pertinence d√©finie
        if 'pertinence' in info:
            score_base = max(score_base, info['pertinence'])
            
        # ‚úÖ VALIDATION ANTI-FAUX POSITIFS
        if 'extraits_textuels' in info:
            score_validite = self._valider_qualite_extraits(info['extraits_textuels'])
            score_base *= score_validite  # R√©duction si extraits peu pertinents
            
        # Bonus selon la source (r√©duits)
        bonus_source = self._get_bonus_source_realiste(source)
        
        # Bonus pour les informations r√©centes (r√©duit)
        bonus_recence = self._get_bonus_recence(info) * 0.5  # Divis√© par 2
        
        score_final = min(score_base + bonus_source + bonus_recence, 0.8)  # Maximum 0.8
        return score_final
    
    def _valider_qualite_extraits(self, extraits_textuels: List[Dict]) -> float:
        """Validation de la qualit√© des extraits trouv√©s"""
        if not extraits_textuels:
            return 0.1
        
        score_qualite = 1.0
        
        for extrait in extraits_textuels:
            titre = extrait.get('titre', '').lower()
            description = extrait.get('description', '').lower()
            url = extrait.get('url', '').lower()
            
            contenu = f"{titre} {description} {url}"
            
            # P√©nalit√©s pour contenu non pertinent
            penalites = [
                ('forum.wordreference.com', -0.8),  # Forums linguistiques
                ('wikipedia.org', -0.3),            # Wikip√©dia g√©n√©raliste
                ('dictionary', -0.6),               # Dictionnaires
                ('translation', -0.6),              # Traductions
                ('grammar', -0.7),                  # Grammaire
                ('linguistique', -0.7),             # Linguistique
                ('definition', -0.5),               # D√©finitions
                ('much or many', -0.9),             # Discussions grammaticales
                ('is/are', -0.9),                   # Questions grammaticales
            ]
            
            for terme_penalite, reduction in penalites:
                if terme_penalite in contenu:
                    score_qualite += reduction
                    print(f"         ‚ö†Ô∏è  P√©nalit√© {terme_penalite}: {reduction}")
            
            # Bonus pour contenu pertinent
            bonus = [
                ('.fr', 0.1),                       # Sites fran√ßais
                ('entreprise', 0.1),                # Contexte entreprise
                ('emploi', 0.2),                    # Emploi
                ('recrutement', 0.2),               # Recrutement
                ('innovation', 0.15),               # Innovation
                ('d√©veloppement', 0.1),             # D√©veloppement
                ('√©conomie', 0.1),                  # √âconomie
            ]
            
            for terme_bonus, augmentation in bonus:
                if terme_bonus in contenu:
                    score_qualite += augmentation
        
        # Score final entre 0.1 et 1.0
        return max(0.1, min(score_qualite, 1.0))
    
    def _get_bonus_source_realiste(self, source: str) -> float:
        """Bonus r√©duits selon la fiabilit√© de la source"""
        bonus = {
            'site_officiel': 0.2,      # R√©duit de 0.3 √† 0.2
            'presse_locale': 0.15,     # R√©duit de 0.2 √† 0.15
            'web_general': 0.05,       # R√©duit de 0.1 √† 0.05
            'enrichissement_insee': 0.1 # Nouveau: donn√©es INSEE enrichies
        }
        return bonus.get(source, 0.0)
    
    def _calculer_score_global(self, resultats_thematiques: Dict) -> float:
        """Calcul du score global avec pond√©ration r√©aliste"""
        scores_valides = []
        
        for thematique, res in resultats_thematiques.items():
            if res['trouve'] and res['score_pertinence'] > 0.3:  # Seuil plus √©lev√©
                scores_valides.append(res['score_pertinence'])
        
        if not scores_valides:
            return 0.0
            
        # Moyenne pond√©r√©e plus conservative
        score_moyen = sum(scores_valides) / len(scores_valides)
        
        # Bonus diversit√© r√©duit
        bonus_diversite = min(len(scores_valides) * 0.02, 0.1)  # Maximum 0.1
        
        # Score final plus r√©aliste
        score_final = min(score_moyen + bonus_diversite, 0.8)  # Maximum 0.8
        
        return score_final    
    
    def _get_bonus_source(self, source: str) -> float:
        """Bonus selon la fiabilit√© de la source"""
        bonus = {
            'site_officiel': 0.3,
            'presse_locale': 0.2,
            'web_general': 0.1,
            'reseaux_sociaux': 0.05
        }
        return bonus.get(source, 0.0)
        
    def _get_bonus_recence(self, info: Dict) -> float:
        """Bonus pour les informations r√©centes"""
        # Pour l'instant, bonus fixe - √† am√©liorer avec vraies dates
        return 0.1
        
    def _extraire_informations(self, info: Dict) -> Dict:
        """Extraction des informations pertinentes"""
        informations = {}
        
        # Mots-cl√©s trouv√©s
        if 'mots_cles_trouves' in info:
            informations['mots_cles'] = info['mots_cles_trouves']
            
        # URL source
        if 'url' in info:
            informations['url'] = info['url']
            
        # Type d'information
        if 'type' in info:
            informations['type'] = info['type']
            
        # Extrait de contenu
        if 'extrait' in info:
            informations['extrait'] = info['extrait'][:200] + '...'
            
        return informations
        
    def _calculer_score_final(self, resultat_thematique: Dict):
        """Calcul du score final pour une th√©matique"""
        if not resultat_thematique['trouve']:
            return
            
        # Bonus pour sources multiples
        nb_sources = len(resultat_thematique['sources'])
        bonus_sources = min(nb_sources * 0.1, 0.3)
        
        # Ajustement du score
        resultat_thematique['score_pertinence'] = min(
            resultat_thematique['score_pertinence'] + bonus_sources, 1.0
        )
        
        # D√©termination du niveau de confiance
        score = resultat_thematique['score_pertinence']
        if score >= 0.8:
            resultat_thematique['niveau_confiance'] = '√âlev√©'
        elif score >= 0.5:
            resultat_thematique['niveau_confiance'] = 'Moyen'
        else:
            resultat_thematique['niveau_confiance'] = 'Faible'
            
    def _calculer_score_global(self, resultats_thematiques: Dict) -> float:
        """Calcul du score global d'activit√© de l'entreprise"""
        scores = [
            res['score_pertinence'] for res in resultats_thematiques.values()
            if res['trouve']
        ]
        
        if not scores:
            return 0.0
            
        # Moyenne pond√©r√©e avec bonus pour diversit√© th√©matique
        score_moyen = sum(scores) / len(scores)
        bonus_diversite = len(scores) * 0.05
        
        return min(score_moyen + bonus_diversite, 1.0)
        
    def _identifier_thematiques_principales(self, resultats_thematiques: Dict) -> List[str]:
        """Identification des th√©matiques principales"""
        thematiques_trouvees = [
            (thematique, res['score_pertinence'])
            for thematique, res in resultats_thematiques.items()
            if res['trouve']
        ]
        
        # Tri par score d√©croissant
        thematiques_trouvees.sort(key=lambda x: x[1], reverse=True)
        
        # Retour des 3 principales
        return [thematique for thematique, _ in thematiques_trouvees[:3]]
        
    def generer_rapport_analyse(self, entreprises_enrichies: List[Dict]) -> Dict:
        """G√©n√©ration d'un rapport d'analyse global"""
        rapport = {
            'timestamp': datetime.now().isoformat(),
            'nb_entreprises_analysees': len(entreprises_enrichies),
            'statistiques_thematiques': {},
            'entreprises_plus_actives': [],
            'resume_par_commune': {}
        }
        
        # Statistiques par th√©matique
        for thematique in self.thematiques:
            nb_entreprises = sum(
                1 for entreprise in entreprises_enrichies
                if entreprise['analyse_thematique'][thematique]['trouve']
            )
            
            rapport['statistiques_thematiques'][thematique] = {
                'nb_entreprises': nb_entreprises,
                'pourcentage': (nb_entreprises / len(entreprises_enrichies)) * 100
            }
            
        # Entreprises les plus actives
        entreprises_scores = [
            (entreprise['nom'], entreprise['score_global'])
            for entreprise in entreprises_enrichies
        ]
        entreprises_scores.sort(key=lambda x: x[1], reverse=True)
        rapport['entreprises_plus_actives'] = entreprises_scores[:5]
        
        # R√©sum√© par commune
        communes = defaultdict(list)
        for entreprise in entreprises_enrichies:
            communes[entreprise['commune']].append(entreprise)
            
        for commune, entreprises in communes.items():
            rapport['resume_par_commune'][commune] = {
                'nb_entreprises': len(entreprises),
                'score_moyen': sum(e['score_global'] for e in entreprises) / len(entreprises),
                'thematiques_dominantes': self._analyser_thematiques_commune(entreprises)
            }
            
        return rapport
        
    def _analyser_thematiques_commune(self, entreprises: List[Dict]) -> List[str]:
        """Analyse des th√©matiques dominantes par commune"""
        compteur_thematiques = Counter()
        
        for entreprise in entreprises:
            for thematique in entreprise['thematiques_principales']:
                compteur_thematiques[thematique] += 1
                
        return [thematique for thematique, _ in compteur_thematiques.most_common(3)]

    def _analyser_source(self, donnees: Dict, source: str, resultats_thematiques: Dict):
        """‚úÖ CORRIG√â : Analyse d'une source de donn√©es avec meilleure gestion des donn√©es"""
        print(f"    üîç Analyse source: {source}")
        
        # ‚úÖ CORRECTION : Gestion des cas o√π donnees est une liste ou dict complexe
        if isinstance(donnees, dict):
            donnees_a_analyser = donnees
        elif isinstance(donnees, list) and len(donnees) > 0:
            # Si c'est une liste, on analyse le premier √©l√©ment significatif
            donnees_a_analyser = donnees[0] if isinstance(donnees[0], dict) else {'extraits_textuels': donnees}
        else:
            print(f"      ‚ö†Ô∏è Donn√©es non analysables pour {source}")
            return
        
        for thematique in self.thematiques:
            if thematique in resultats_thematiques:
                print(f"      üéØ Analyse th√©matique: {thematique}")
                
                # ‚úÖ NOUVEAU : Analyse adapt√©e selon la structure des donn√©es
                score = self._calculer_score_pertinence_adapte(donnees_a_analyser, source, thematique)
                print(f"         üíØ Score calcul√©: {score:.2f}")
                
                if score > self.seuil_pertinence:
                    print(f"         ‚úÖ Score > seuil ({self.seuil_pertinence})")
                    
                    resultats_thematiques[thematique]['trouve'] = True
                    resultats_thematiques[thematique]['score_pertinence'] = max(
                        resultats_thematiques[thematique]['score_pertinence'], score
                    )
                    
                    # Ajout de la source
                    if source not in resultats_thematiques[thematique]['sources']:
                        resultats_thematiques[thematique]['sources'].append(source)
                    
                    # ‚úÖ EXTRACTION ADAPT√âE DES INFORMATIONS
                    informations_extraites = self._extraire_informations_adaptees(donnees_a_analyser, source)
                    
                    # Ajout des d√©tails avec TOUTES les informations
                    detail = {
                        'source': source,
                        'score': score,
                        'informations': informations_extraites,
                        'timestamp': datetime.now().isoformat(),
                        'raw_data': donnees_a_analyser
                    }
                    resultats_thematiques[thematique]['details'].append(detail)
                    
                    print(f"         üìä Informations extraites: {len(informations_extraites)} cl√©s")
                else:
                    print(f"         ‚ö™ Score trop faible ({score:.2f} <= {self.seuil_pertinence})")

    def _calculer_score_pertinence_adapte(self, donnees: Dict, source: str, thematique: str) -> float:
        """‚úÖ NOUVEAU : Calcul de score adapt√© aux vraies donn√©es de votre syst√®me"""
        score_base = 0.0
        
        # 1. ‚úÖ Analyse des mots-cl√©s trouv√©s (si disponible)
        if 'mots_cles_trouves' in donnees:
            nb_mots_cles = len(donnees['mots_cles_trouves'])
            score_base = min(nb_mots_cles * 0.2, 0.6)
            print(f"           üîë Mots-cl√©s trouv√©s: {donnees['mots_cles_trouves']}")
        
        # 2. ‚úÖ Analyse de la pertinence d√©finie (si disponible)
        if 'pertinence' in donnees:
            score_base = max(score_base, donnees['pertinence'])
            print(f"           üìä Pertinence d√©finie: {donnees['pertinence']}")
        
        # 3. ‚úÖ NOUVEAU : Analyse des extraits textuels
        if 'extraits_textuels' in donnees:
            extraits = donnees['extraits_textuels']
            if isinstance(extraits, list) and len(extraits) > 0:
                score_extraits = self._analyser_extraits_pour_thematique(extraits, thematique)
                score_base = max(score_base, score_extraits)
                print(f"           üìÑ Score extraits: {score_extraits:.2f}")
        
        # 4. ‚úÖ NOUVEAU : Analyse du contenu textuel direct
        contenu_textuel = self._extraire_contenu_textuel(donnees)
        if contenu_textuel:
            score_contenu = self._analyser_contenu_thematique(contenu_textuel, thematique)
            score_base = max(score_base, score_contenu)
            print(f"           üìù Score contenu: {score_contenu:.2f}")
        
        # 5. Bonus selon la source (r√©duits mais pr√©sents)
        bonus_source = self._get_bonus_source_realiste(source)
        
        # 6. Score final conservateur mais fonctionnel
        score_final = min(score_base + bonus_source, 0.8)
        return score_final

    def _analyser_extraits_pour_thematique(self, extraits: List, thematique: str) -> float:
        """‚úÖ NOUVEAU : Analyse sp√©cifique des extraits pour une th√©matique"""
        if not extraits:
            return 0.0
        
        mots_cles_thematique = self.config.get(thematique, [])
        if not mots_cles_thematique:
            return 0.0
        
        score_total = 0.0
        
        for extrait in extraits[:5]:  # Analyser max 5 extraits
            texte_extrait = ""
            
            # Extraction du texte selon la structure
            if isinstance(extrait, dict):
                texte_extrait = f"{extrait.get('titre', '')} {extrait.get('description', '')} {extrait.get('extrait_complet', '')}"
            elif isinstance(extrait, str):
                texte_extrait = extrait
            else:
                continue
            
            texte_extrait = texte_extrait.lower()
            
            # Comptage des mots-cl√©s th√©matiques trouv√©s
            mots_trouves = [mot for mot in mots_cles_thematique if mot.lower() in texte_extrait]
            
            if mots_trouves:
                score_extrait = min(len(mots_trouves) * 0.15, 0.4)
                score_total += score_extrait
                print(f"             üìã Extrait: {len(mots_trouves)} mots-cl√©s ‚Üí {score_extrait:.2f}")
        
        return min(score_total, 0.7)

    def _analyser_contenu_thematique(self, contenu: str, thematique: str) -> float:
        """‚úÖ NOUVEAU : Analyse th√©matique directe du contenu textuel"""
        if not contenu or len(contenu) < 10:
            return 0.0
        
        contenu_lower = contenu.lower()
        mots_cles_thematique = self.config.get(thematique, [])
        
        score_contenu = 0.0
        
        for mot_cle in mots_cles_thematique:
            if mot_cle.lower() in contenu_lower:
                score_contenu += 0.1
                print(f"             üéØ Mot-cl√© '{mot_cle}' trouv√©")
        
        return min(score_contenu, 0.5)

    def _extraire_contenu_textuel(self, donnees: Dict) -> str:
        """‚úÖ NOUVEAU : Extraction du contenu textuel depuis les donn√©es"""
        contenu_parts = []
        
        # Sources possibles de contenu textuel
        champs_texte = [
            'titre', 'description', 'extrait_complet', 'resume_contenu',
            'texte', 'contenu', 'snippet'
        ]
        
        for champ in champs_texte:
            if champ in donnees and isinstance(donnees[champ], str):
                contenu_parts.append(donnees[champ])
        
        # Extraction depuis les extraits textuels
        if 'extraits_textuels' in donnees:
            extraits = donnees['extraits_textuels']
            if isinstance(extraits, list):
                for extrait in extraits[:3]:  # Max 3 extraits
                    if isinstance(extrait, dict):
                        for champ in champs_texte:
                            if champ in extrait and isinstance(extrait[champ], str):
                                contenu_parts.append(extrait[champ])
        
        return ' '.join(contenu_parts)

    def _extraire_informations_adaptees(self, donnees: Dict, source: str) -> Dict:
        """‚úÖ NOUVEAU : Extraction d'informations adapt√©e √† vos structures de donn√©es"""
        informations = {
            'source': source,
            'timestamp': datetime.now().isoformat()
        }
        
        # 1. Extraction des champs standard
        champs_standards = [
            'mots_cles_trouves', 'pertinence', 'url', 'type', 'urls',
            'titre', 'description', 'extrait_complet'
        ]
        
        for champ in champs_standards:
            if champ in donnees:
                informations[champ] = donnees[champ]
        
        # 2. ‚úÖ Gestion sp√©ciale des extraits textuels
        if 'extraits_textuels' in donnees:
            extraits = donnees['extraits_textuels']
            if isinstance(extraits, list) and len(extraits) > 0:
                informations['extraits_textuels'] = extraits[:3]  # Top 3
                
                # R√©sum√© des extraits
                titres = []
                descriptions = []
                
                for extrait in extraits[:3]:
                    if isinstance(extrait, dict):
                        if 'titre' in extrait:
                            titres.append(extrait['titre'])
                        if 'description' in extrait:
                            descriptions.append(extrait['description'])
                
                if titres:
                    informations['resume_titres'] = ' | '.join(titres)
                if descriptions:
                    informations['resume_descriptions'] = ' | '.join(descriptions)
        
        # 3. ‚úÖ M√©tadonn√©es suppl√©mentaires
        informations['nb_champs_remplis'] = len([v for v in informations.values() if v])
        informations['qualite_donnees'] = 'elevee' if len(informations) > 5 else 'moyenne'
        
        return informations

    # ‚úÖ M√âTHODE PRINCIPALE CORRIG√âE pour r√©soudre le probl√®me de structure
    def analyser_resultats(self, resultats_bruts: List[Dict], logger=None) -> List[Dict]:
        """‚úÖ VERSION FINALE CORRIG√âE : Analyse adapt√©e au format exact de vos donn√©es"""
        print("üî¨ Analyse th√©matique des r√©sultats (VERSION CORRIG√âE FINALE)")
        
        entreprises_enrichies = []
        
        for i, resultat in enumerate(resultats_bruts, 1):
            nom_entreprise = resultat.get('entreprise', {}).get('nom', f'Entreprise_{i}')
            print(f"  üìä Analyse {i}/{len(resultats_bruts)}: {nom_entreprise}")
            
            try:
                # V√©rification des donn√©es
                donnees_thematiques = resultat.get('donnees_thematiques', {})
                
                if not donnees_thematiques:
                    print(f"    ‚ö†Ô∏è Aucune donn√©e th√©matique")
                    # Structure minimale
                    entreprise_base = resultat.get('entreprise', {})
                    entreprise_base.update({
                        'analyse_thematique': {thematique: {'trouve': False, 'score_pertinence': 0.0} for thematique in self.thematiques},
                        'score_global': 0.0,
                        'thematiques_principales': [],
                        'date_analyse': datetime.now().isoformat()
                    })
                    entreprises_enrichies.append(entreprise_base)
                    continue
                
                # Analyse avec la m√©thode corrig√©e
                entreprise_enrichie = self._analyser_entreprise(resultat)
                entreprises_enrichies.append(entreprise_enrichie)
                
                # Logging des r√©sultats
                if logger:
                    thematiques_detectees = entreprise_enrichie.get('thematiques_principales', [])
                    score_global = entreprise_enrichie.get('score_global', 0.0)
                    
                    logger.log_analyse_thematique(
                        nom_entreprise=nom_entreprise,
                        thematiques=thematiques_detectees,
                        score=score_global
                    )
                    
                    if score_global > 0.0:
                        print(f"    üéâ SUCC√àS: {nom_entreprise} ‚Üí score {score_global:.3f}")
                
            except Exception as e:
                print(f"    ‚ùå Erreur analyse {nom_entreprise}: {e}")
                import traceback
                traceback.print_exc()
                
                if logger:
                    logger.log_analyse_thematique(nom_entreprise, [], 0.0, erreurs=[str(e)])
                
                # Structure d'erreur
                entreprise_base = resultat.get('entreprise', {})
                entreprise_base.update({
                    'analyse_thematique': {thematique: {'trouve': False, 'score_pertinence': 0.0} for thematique in self.thematiques},
                    'score_global': 0.0,
                    'thematiques_principales': [],
                    'date_analyse': datetime.now().isoformat(),
                    'erreur_analyse': str(e)
                })
                entreprises_enrichies.append(entreprise_base)
                continue
        
        # Statistiques de d√©tection
        entreprises_actives = [e for e in entreprises_enrichies if e.get('score_global', 0) > 0.2]
        entreprises_tres_actives = [e for e in entreprises_enrichies if e.get('score_global', 0) > 0.5]
        
        print(f"‚úÖ Analyse termin√©e pour {len(entreprises_enrichies)} entreprises")
        print(f"üéØ Entreprises actives (>0.2): {len(entreprises_actives)}")
        print(f"üèÜ Entreprises tr√®s actives (>0.5): {len(entreprises_tres_actives)}")
        
        if len(entreprises_actives) > 0:
            print("üéâ SUCC√àS : Entreprises d√©tect√©es !")
            for ent in entreprises_actives[:3]:
                nom = ent.get('nom', 'N/A')
                score = ent.get('score_global', 0)
                themes = ent.get('thematiques_principales', [])
                print(f"    ‚Ä¢ {nom}: {score:.3f} ‚Üí {themes}")
        
        return entreprises_enrichies
    
    def _analyser_entreprise_adaptee(self, resultat: Dict) -> Dict:
        """‚úÖ NOUVEAU : Analyse d'entreprise adapt√©e aux donn√©es r√©elles"""
        entreprise = resultat.get('entreprise', {}).copy()
        
        # Initialisation des r√©sultats th√©matiques
        resultats_thematiques = {
            thematique: {
                'trouve': False,
                'score_pertinence': 0.0,
                'sources': [],
                'details': [],
                'derniere_mention': None
            }
            for thematique in self.thematiques
        }
        
        # ‚úÖ NOUVEAU : Analyse des donn√©es par source avec gestion robuste
        donnees_thematiques = resultat.get('donnees_thematiques', {})
        
        for source, donnees in donnees_thematiques.items():
            print(f"    üîç Traitement source: {source}")
            
            # ‚úÖ Gestion robuste des diff√©rents formats de donn√©es
            if isinstance(donnees, dict):
                # Format standard : {'thematique': {...}}
                for thematique_key, thematique_data in donnees.items():
                    if thematique_key in self.thematiques:
                        self._analyser_donnee_thematique(
                            thematique_key, thematique_data, source, resultats_thematiques
                        )
            elif isinstance(donnees, list):
                # Format liste : traiter comme donn√©es g√©n√©rales
                print(f"      üìã Donn√©es format liste: {len(donnees)} √©l√©ments")
                for thematique in self.thematiques:
                    score = self._analyser_liste_donnees(donnees, thematique)
                    if score > self.seuil_pertinence:
                        resultats_thematiques[thematique]['trouve'] = True
                        resultats_thematiques[thematique]['score_pertinence'] = score
                        resultats_thematiques[thematique]['sources'].append(source)
        
        # Calcul des scores finaux
        for thematique in resultats_thematiques:
            self._calculer_score_final(resultats_thematiques[thematique])
        
        # Ajout des r√©sultats √† l'entreprise
        entreprise['analyse_thematique'] = resultats_thematiques
        entreprise['score_global'] = self._calculer_score_global(resultats_thematiques)
        entreprise['thematiques_principales'] = self._identifier_thematiques_principales(resultats_thematiques)
        entreprise['date_analyse'] = datetime.now().isoformat()
        
        return entreprise

    def _analyser_donnee_thematique(self, thematique: str, donnee: Dict, source: str, resultats_thematiques: Dict):
        """‚úÖ NOUVEAU : Analyse d'une donn√©e th√©matique sp√©cifique"""
        if not isinstance(donnee, dict):
            return
        
        # Calcul du score de pertinence
        score = self._calculer_score_pertinence_adapte(donnee, source, thematique)
        
        if score > self.seuil_pertinence:
            print(f"      ‚úÖ {thematique}: score {score:.2f}")
            
            resultats_thematiques[thematique]['trouve'] = True
            resultats_thematiques[thematique]['score_pertinence'] = max(
                resultats_thematiques[thematique]['score_pertinence'], score
            )
            
            if source not in resultats_thematiques[thematique]['sources']:
                resultats_thematiques[thematique]['sources'].append(source)
            
            # Ajout des d√©tails
            detail = {
                'source': source,
                'score': score,
                'informations': self._extraire_informations_adaptees(donnee, source),
                'timestamp': datetime.now().isoformat()
            }
            resultats_thematiques[thematique]['details'].append(detail)
        else:
            print(f"      ‚ö™ {thematique}: score {score:.2f} (< {self.seuil_pertinence})")

    def _analyser_liste_donnees(self, donnees: List, thematique: str) -> float:
        """‚úÖ NOUVEAU : Analyse d'une liste de donn√©es pour une th√©matique"""
        if not donnees:
            return 0.0
        
        score_total = 0.0
        mots_cles_thematique = self.config.get(thematique, [])
        
        for donnee in donnees[:5]:  # Max 5 √©l√©ments
            if isinstance(donnee, dict):
                contenu = self._extraire_contenu_textuel(donnee)
                if contenu:
                    score_element = self._analyser_contenu_thematique(contenu, thematique)
                    score_total += score_element
            elif isinstance(donnee, str):
                score_element = self._analyser_contenu_thematique(donnee, thematique)
                score_total += score_element
        
        return min(score_total, 0.6)